#!/usr/bin/env python

"""

    darcs-fast-export - darcs backend for fast data importers

    Copyright (c) 2008 Miklos Vajna <vmiklos@frugalware.org>
    Copyright (c) 2008 Matthias Andree <matthias.andree@gmx.de>

    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation; either version 2, or (at your option)
    any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program; if not, write to the Free Software
    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.

"""

import xml.dom.minidom
import xml.parsers.expat
import os
import sys
import gzip
import time
import shutil
import subprocess
import optparse
import re

sys = reload(sys)
sys.setdefaultencoding("utf-8")

def __get_zone():
	now = time.localtime()
	if time.daylight and now[-1]:
		offset = time.altzone
	else:
		offset = time.timezone
	hours, minutes = divmod(abs(offset), 3600)
	if offset > 0:
		sign = "-"
	else:
		sign = "+"
	return sign, hours, minutes

def get_zone_str():
	sign, hours, minutes = __get_zone()
	return "%s%02d%02d" % (sign, hours, minutes // 60)

def get_zone_int():
	sign, hours, minutes = __get_zone()
	ret = hours*3600+minutes*60
	if sign == "-":
		ret *= -1
	return ret

def get_patchname(patch):
	ret = []
	s = ""
	if patch.attributes['inverted'].value == 'True':
		s = "UNDO: "
	ret.append(s + patch.getElementsByTagName("name")[0].childNodes[0].data)
	lines = patch.getElementsByTagName("comment")
	if lines:
		for i in lines[0].childNodes[0].data.split('\n'):
			if not i.startswith("Ignore-this: "):
				ret.append(i)
	if len(ret) > 1:
		ret.insert(1, u"")
	return "\n".join(ret).encode('utf-8')

def get_author(patch):
	"""darcs allows any freeform string, but fast-import has a more
	strict format, so fix up broken author names here."""

	author = patch.attributes['author'].value
	if author in authormap:
		author = authormap[author]
	if not len(author):
		author = "darcs-fast-export <darcs-fast-export>"
	# add missing name
	elif not ">" in author:
		author = "%s <%s>" % (author.split('@')[0], author)
	# avoid double quoting
	elif author[0] == '"' and author[-1] == '"':
		author = author[1:-1]
	# name after email
	elif author[-1] != '>':
		author = author[author.index('>')+2:] + ' ' + author[:author.index('>')+1]
	return author.encode('utf-8')

def get_date(patch):
	try:
		date = time.strptime(patch, "%Y%m%d%H%M%S")
	except ValueError:
		date = time.strptime(patch[:19] + patch[-5:], '%a %b %d %H:%M:%S %Y')
	return int(time.mktime(date)) + get_zone_int()

def progress(s):
	print "progress [%s] %s" % (time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()), s)
	sys.stdout.flush()

def log(s):
	logsock.write("[%s] %s" % (time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()), s))
	logsock.flush()

hashes = []
def parse_inventory(sock=None):
	prev = None
	nextprev = False
	buf = []
	if not sock:
		sock = open(os.path.join("_darcs", "hashed_inventory"))
	for i in sock.readlines():
		if i.startswith("hash"):
			buf.insert(0, i[6:-1])
		if i.startswith("Starting with inventory:"):
			nextprev = True
		elif nextprev:
			prev = i[:-1]
			nextprev = False
	sock.close()
	for i in buf:
		hashes.insert(0, i)
	if prev:
		sock = gzip.open(os.path.join("_darcs", "inventories", prev))
		parse_inventory(sock)

# Option Parser
usage="%prog [options] darcsrepo"
opp = optparse.OptionParser(usage=usage)
opp.add_option("--import-marks", metavar="IFILE",
	help="read state for incremental imports from IFILE")
opp.add_option("--export-marks", metavar="OFILE",
	help="write state for incremental imports from OFILE")
opp.add_option("--encoding",
	help="encoding of log [default: %default], if unspecified and input isn't utf-8, guess")
opp.add_option("--authors-file", metavar="F",
	help="read author transformations in old=new format from F")
opp.add_option("--working", metavar="W",
	help="working directory which is removed at the end of non-incremental conversions")
opp.add_option("--logfile", metavar="L",
	help="log file which contains the output of external programs invoked during the conversion")
opp.add_option("--git-branch", metavar="B",
	help="git branch [default: refs/heads/master]")
opp.add_option("--progress", metavar="P",
	help="insert progress statements after every n commit [default: 100]")
(options, args) = opp.parse_args()
if len(args) < 1:
	opp.error("darcsrepo required")

export_marks = []
import_marks = []
if options.import_marks:
	sock = open(options.import_marks)
	for i in sock.readlines():
		line = i.strip()
		if not len(line):
			continue
		import_marks.append(line.split(' ')[1])
		export_marks.append(line)
	sock.close()

# read author mapping file in gitauthors format,
# i. e. in=out (one per # line)
authormap = {}
if options.authors_file:
	sock = open(options.authors_file)
	authormap = dict([i.strip().split('=',1) for i in sock])
	sock.close()

origin = os.path.abspath(args[0])
if options.working:
	working = os.path.abspath(options.working)
else:
	working = "%s.darcs" % origin
patchfile = "%s.patch" % origin
if options.logfile:
	logfile = os.path.abspath(options.logfile)
else:
	logfile = "%s.log" % origin
logsock = open(logfile, "a")
if options.git_branch:
	git_branch = options.git_branch
else:
	git_branch = "refs/heads/master"

if options.progress:
	prognum = int(options.progress)
else:
	prognum = 100

progress("getting list of patches")
if not len(import_marks):
	sock = os.popen("darcs changes --xml --reverse --repo %s" % origin)
else:
	sock = os.popen("darcs changes --xml --reverse  --repo %s --from-match 'hash %s'" % (origin, import_marks[-1]))
buf = sock.read()
sock.close()
# this is hackish. we need to escape some bad chars, otherwise the xml
# will not be valid
buf = buf.replace('\x1b', '^[')
if options.encoding:
	xmldoc = xml.dom.minidom.parseString(unicode(buf, options.encoding).encode('utf-8'))
else:
	try:
		xmldoc = xml.dom.minidom.parseString(buf)
	except xml.parsers.expat.ExpatError:
		import chardet
		progress("encoding is not utf8, guessing charset")
		encoding = chardet.detect(buf)['encoding']
		progress("detected encoding is %s" % encoding)
		xmldoc = xml.dom.minidom.parseString(unicode(buf, encoding).encode('utf-8'))
sys.stdout.flush()

darcs2 = False
oldfashionedpatch = True
cwd = os.getcwd()
if os.path.exists(os.path.join(origin, "_darcs", "format")):
	sock = open(os.path.join(origin, "_darcs", "format"))
	format = [x.strip() for x in sock]
	sock.close()
	darcs2 = 'darcs-2' in format
	oldfashionedpatch = not 'hashed' in format
if not oldfashionedpatch:
	progress("parsing the inventory")
	os.chdir(origin)
	parse_inventory()
if not options.import_marks or not os.path.exists(working):
	# init the tmp darcs repo
	os.mkdir(working)
	os.chdir(working)
	if darcs2:
		os.system("darcs init --darcs-2")
	else:
		os.system("darcs init --old-fashioned-inventory")
else:
	os.chdir(working)
if options.import_marks:
	sock = os.popen("darcs pull -a --match 'hash %s' %s" % (import_marks[-1], origin))
	# note that this only pulls in one patch, not others that might sit
	# before it. I think it was intended to update the --working repo up
	# to the point we were at after the previous dfe run. This will fail
	# if we've pushed (git-to-darcs) more than one non-interdependent
	# patch since the last pull (darcs-to-git): this will pull the latest
	# one, but not the ones before that.
	#  start:
	#   darcs=AB, --working=AB, git=AB, import_marks[-1]=B
	#  add C,D to git
	#   darcs=AB, --working=AB, git=ABCD, import_marks[-1]=B
	#  push git-to-darcs (git-fast-export|darcs-fast-import), pushes C+D
	#   darcs=ABCD, --working=AB, git=ABCD, import_marks[-1]=D
	#  add E to darcs
	#   darcs=ABCDE, --working=AB, git=ABCD, import_marks[-1]=D
	#  pull darcs-to-git (darcs-fast-export|git-fast-import)
	#   this 'darcs pull' pulls D (the last thing pushed to darcs)
	#   darcs=ABCDE, --working=ABD, git=ABCD, import_marks[-1]=D
	#   then send/apply E
	#   darcs=ABCDE, --working=ABDE, git=ABCD, import_marks[-1]=D
	#   then the state of all files are copied into git state E, reverting
	#    the D-provided git patch (so git[E] = A+B+C+E = darcs[E]-D)
	#   darcs=ABCDE, --working=ABDE, git=ABCE, import_marks[-1]=E

	# really, we want to keep the --working repo up to date. To do that
	# on just the darcs-to-git direction is tricky. We need to know not
	# only the last entry in import_marks[], but every entry that was
	# added by git-to-darcs since the last time we updated this repo.

	# one possibility is to record the mark number of import_marks[-1] at
	# the end of darcs darcs-to-git run. Then, at the begnning of the
	# next run, find everything that's listed past that. None of these
	# should be in the --working repo yet: they all came from git and
	# were sent over to darcs by git-to-darcs. Pull all of those into
	# --working; now this repo is up-to-date. Then, check to see what the
	# darcs repo has for us, and apply+transfer them one at a time.
	# Update import_marks at the end of this process.
	#
	# store the number.. somewhere.

	log("Building/updating working directory:\n%s" % sock.read())
	sock.close()

# this is the number of the NEXT patch
count = 1
patches = xmldoc.getElementsByTagName('patch')
if len(import_marks):
	patches = patches[1:]
	count = len(import_marks) + 1
if len(export_marks):
	# this is the mark number of the NEXT patch
	markcount = int(export_marks[-1].split(' ')[0][1:]) + 1
else:
	markcount = count
# this may be huge and we need it many times
patchnum = len(patches)

if not len(import_marks):
	progress("starting export, repo has %d patches" % patchnum)
else:
	progress("continuing export, %d patches to convert" % patchnum)
for i in patches:
	# apply the patch
	hash = i.attributes['hash'].value
	buf = ["\nNew patches:\n"]
	if oldfashionedpatch:
		sock = gzip.open(os.path.join(origin, "_darcs", "patches", hash))
	else:
		sock = gzip.open(os.path.join(origin, "_darcs", "patches", hashes[count-1]))
	buf.append(sock.read())
	sock.close()
	sock = os.popen("darcs changes --context")
	buf.append(sock.read())
	sock.close()
	sock = subprocess.Popen(["darcs", "apply", "--allow-conflicts"], stdin=subprocess.PIPE, stdout=subprocess.PIPE)
	sock.stdin.write("".join(buf))
	sock.stdin.close()
	log("Applying %s:\n%s" % (hash, sock.stdout.read()))
	sock.stdout.close()
	message = get_patchname(i)
	# export the commit
	print "commit %s" % git_branch
	print "mark :%s" % markcount
	if options.export_marks:
		export_marks.append(":%s %s" % (markcount, hash))
	date = get_date(i.attributes['date'].value)
	print "committer %s %s %s" % (get_author(i), date, get_zone_str())
	print "data %d\n%s" % (len(message), message)
	if markcount > 1:
		print "from :%s" % (markcount-1)
	# export the files
	print "deleteall"
	for (root, dirs, files) in os.walk ("."):
		for f in files:
			j = os.path.normpath(os.path.join(root, f))
			if j.startswith("_darcs") or "-darcs-backup" in j:
				continue
			sock = open(j)
			buf = sock.read()
			sock.close()
			# darcs does not track the executable bit :/
			print "M 644 inline %s" % j
			print "data %s\n%s" % (len(buf), buf)
	if message[:4] == "TAG ":
		tag = re.sub('[^\xe9-\xf8\w.\-]+', '_', message[4:].strip().split('\n')[0]).strip('_')
		print "tag %s" % tag
		print "from :%s" % markcount
		print "tagger %s %s %s" % (get_author(i), date, get_zone_str())
		print "data %d\n%s" % (len(message), message)
	if count % prognum == 0:
		progress("%d/%d patches" % (count, patchnum))
	count += 1
	markcount += 1

os.chdir(cwd)

if not options.export_marks:
	shutil.rmtree(working)
logsock.close()

if options.export_marks:
	progress("writing export marks")
	sock = open(options.export_marks, 'w')
	sock.write("\n".join(export_marks))
	sock.write("\n")
	sock.close()

progress("finished")
